{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Models\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "To get started, connect to your workspace.\n",
        "\n",
        "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip install argparse"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: argparse in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (1.4.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646829651378
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "               \n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.38.0 to work with machinelearningfinal\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1646829652723
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "if 'house prices dataset' not in ws.datasets:\n",
        "    default_ds.upload_files(files=['./data/over 5 years.csv'], # Upload the diabetes csv files in /data\n",
        "                        target_path='house-prices-data/', # Put it in a folder path in the datastore\n",
        "                        overwrite=True, # Replace existing files of the same name\n",
        "                        show_progress=True)\n",
        "\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'house-prices-data/*.csv'))\n",
        "\n",
        "    # Register the tabular dataset\n",
        "    try:\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name='house prices dataset',\n",
        "                                description='house prices data',\n",
        "                                tags = {'format':'CSV'},\n",
        "                                create_new_version=True)\n",
        "        print('Dataset registered.')\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print('Dataset already registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset already registered.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646829653406
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create scripts for pipeline steps"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Create a folder for the pipeline step files\n",
        "experiment_folder = 'house_prediction_pipeline'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "house_prediction_pipeline\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646829653860
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare compute env"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep and training steps"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/prep_houses.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from azureml.core import Run\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
        "args = parser.parse_args()\n",
        "save_folder = args.prepped_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the data (passed as an input dataset)\n",
        "print(\"Loading Data...\")\n",
        "houses = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
        "\n",
        "# Log raw row count\n",
        "row_count = (len(houses))\n",
        "run.log('raw_rows', row_count)\n",
        "\n",
        "# remove nulls\n",
        "houses = houses.dropna()\n",
        "\n",
        "# Normalize the numeric columns\n",
        "scaler = MinMaxScaler()\n",
        "num_cols = ['nombre_pieces_principales','surface_terrain','surface_reelle_bati']\n",
        "houses[num_cols] = scaler.fit_transform(houses[num_cols])\n",
        "\n",
        "# Log processed rows\n",
        "row_count = (len(houses))\n",
        "run.log('processed_rows', row_count)\n",
        "\n",
        "# Save the prepped data\n",
        "print(\"Saving Data...\")\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "save_path = os.path.join(save_folder,'data.csv')\n",
        "houses.to_csv(save_path, index=False, header=True)\n",
        "\n",
        "# End the run\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting house_prediction_pipeline/prep_houses.py\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/houses_pricing-training.py\n",
        "# Import libraries\n",
        "from azureml.core import Run,Model\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression,Lasso\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\n",
        "args = parser.parse_args()\n",
        "training_data = args.training_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "file_path = os.path.join(training_data,'data.csv')\n",
        "houses = pd.read_csv(file_path)\n",
        "\n",
        "# Separate features and predicted result\n",
        "X = houses[['nombre_pieces_principales','surface_terrain','surface_reelle_bati']]\n",
        "y = houses['valeur_fonciere']\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "\n",
        "model = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "# calculate r2\n",
        "y_pred = model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred, multioutput='variance_weighted')\n",
        "print('R2: ' + str(r2))\n",
        "run.log('R2', np.float(r2))\n",
        "\n",
        "# calculate mse\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('MSE:' + str(mse))\n",
        "run.log('MSE', np.float(mse))\n",
        "\n",
        "# calculate mae (mean absolute error)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print('MAE:' + str(mae))\n",
        "run.log('MAE', np.float(mae))\n",
        "\n",
        "# Save the trained model in the outputs folder\n",
        "print(\"Saving model...\")\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "model_file = os.path.join('outputs', 'house_prices_model.pkl')\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "# Register the model\n",
        "print('Registering model...')\n",
        "Model.register(workspace=run.experiment.workspace,\n",
        "               model_path = model_file,\n",
        "               model_name = 'house-prices_model',\n",
        "               tags={'Training context':'Pipeline'},\n",
        "               properties={'R2': np.float(r2), 'MSE': np.float(mse), 'MAE': np.float(mae)})\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting house_prediction_pipeline/houses_pricing-training.py\n"
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"your-compute-cluster\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646829655184
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/experiment_env.yml\n",
        "name: experiment_env\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- ipykernel\n",
        "- matplotlib\n",
        "- pandas\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - pyarrow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting house_prediction_pipeline/experiment_env.yml\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\n",
        "\n",
        "# Register the environment \n",
        "experiment_env.register(workspace=ws)\n",
        "registered_env = Environment.get(ws, 'experiment_env')\n",
        "\n",
        "# Create a new runconfig object for the pipeline\n",
        "pipeline_run_config = RunConfiguration()\n",
        "\n",
        "# Use the compute you created above. \n",
        "pipeline_run_config.target = pipeline_cluster\n",
        "\n",
        "# Assign the environment to the run configuration\n",
        "pipeline_run_config.environment = registered_env\n",
        "\n",
        "print (\"Run configuration created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run configuration created.\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646829656053
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and run a pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "\n",
        "# Get the training dataset\n",
        "houses_ds = ws.datasets.get(\"house prices dataset\")\n",
        "\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
        "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\n",
        "\n",
        "# Step 1, Run the data prep script\n",
        "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"prep_houses.py\",\n",
        "                                arguments = ['--input-data', houses_ds.as_named_input('raw_data'),\n",
        "                                             '--prepped-data', prepped_data],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "# Step 2, run the training script\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"houses_pricing-training.py\",\n",
        "                                arguments = ['--training-data', prepped_data.as_input()],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline steps defined\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646829656528
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import RegressionPipeline, Pipeline\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Construct the pipeline\n",
        "pipeline_steps = [prep_step, train_step]\n",
        "pipeline=Pipeline(memory=None,steps=[('datatransformer', DataTransformer(\n",
        "    enable_dnn=False, enable_feature_sweeping=True, feature_sweeping_config={}, \n",
        "    feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, \n",
        "    is_onnx_compatible=False, observer=None, task='regression', working_dir='/mnt/batch/ta'), \n",
        "    \n",
        "    random_state=0, reg_alpha=2.3958333333333335, reg_lambda=1.7708333333333335, subsample=1, tree_method='auto'))], verbose=False))\n",
        "    \n",
        "    RegressionPipeline(pipeline, ('17', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('decisiontreeregressor', DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None, max_features=0.9, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.00218714609400816, min_samples_split=0.0037087774117744725, min_weight_fraction_leaf=0.0, presort='deprecated', random_state=None, splitter='best'))], verbose=False)), ('12', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('extratreesregressor', ExtraTreesRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae', max_depth=None, max_features=0.8, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01091729022778783, min_samples_split=0.001529732116091358, min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False))], weights=[0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.26666666666666666, 0.4666666666666667, 0.06666666666666667]))],\n",
        "            verbose=False),\n",
        "            stddev=[2472902.6566388463])                   \n",
        "print(\"Pipeline is built.\")\n",
        "\n",
        "# Create an experiment and run the pipeline\n",
        "experiment = Experiment(workspace=ws, name = 'mslearn-house-price_prediction-pipeline')\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
        "print(\"Pipeline submitted for execution.\")\n",
        "RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-11-b0f621b5caa1>, line 10)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-b0f621b5caa1>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    ), random_state=0, reg_alpha=2.3958333333333335, reg_lambda=1.7708333333333335, subsample=1, tree_method='auto'))], verbose=False)), ('17', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('decisiontreeregressor', DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None, max_features=0.9, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.00218714609400816, min_samples_split=0.0037087774117744725, min_weight_fraction_leaf=0.0, presort='deprecated', random_state=None, splitter='best'))], verbose=False)), ('12', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('extratreesregressor', ExtraTreesRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae', max_depth=None, max_features=0.8, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01091729022778783, min_samples_split=0.001529732116091358, min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False))], weights=[0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.26666666666666666, 0.4666666666666667, 0.06666666666666667]))],\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646783652656
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publish the pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Publish the pipeline from the run\n",
        "published_pipeline = pipeline_run.publish_pipeline(\n",
        "    name=\"house-prices-prediction-training-pipeline\", description=\"Trains houses prices model\", version=\"1.0\")\n",
        "\n",
        "published_pipeline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646783653293
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\n",
        "print(rest_endpoint)\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "interactive_auth = InteractiveLoginAuthentication()\n",
        "auth_header = interactive_auth.get_authentication_header()\n",
        "print(\"Authentication header ready.\")\n",
        "import requests\n",
        "\n",
        "experiment_name = 'mslearn-house-pipeline'\n",
        "\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=auth_header, \n",
        "                         json={\"ExperimentName\": experiment_name})\n",
        "run_id = response.json()[\"Id\"]\n",
        "from azureml.pipeline.core.run import PipelineRun\n",
        "\n",
        "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
        "published_pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646783658021
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
        "\n",
        "# Submit the Pipeline every Monday at 00:00 UTC\n",
        "recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, week_days=[\"Monday\"], time_of_day=\"00:00\")\n",
        "weekly_schedule = Schedule.create(ws, name=\"weekly-house-training\", \n",
        "                                  description=\"Based on time\",\n",
        "                                  pipeline_id=published_pipeline.id, \n",
        "                                  experiment_name='mslearn-house-pipeline', \n",
        "                                  recurrence=recurrence)\n",
        "print('Pipeline scheduled.')\n",
        "schedules = Schedule.list(ws)\n",
        "pipeline_experiment = ws.experiments.get('mslearn-house-pipeline')\n",
        "latest_run = list(pipeline_experiment.get_runs())[0]\n",
        "\n",
        "latest_run.get_details()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646783670897
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can retrieve the metrics and outputs from the **Run** object."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "for run in pipeline_run.get_children():\n",
        "    print(run.name, ':')\n",
        "    metrics = run.get_metrics()\n",
        "    for metric_name in metrics:\n",
        "        print('\\t',metric_name, \":\", metrics[metric_name])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1646783672415
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646783672909
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Publish the pipeline from the run\n",
        "published_pipeline = pipeline_run.publish_pipeline(\n",
        "    name=\"house-training-pipeline\", description=\"Trains house model\", version=\"1.0\")\n",
        "\n",
        "published_pipeline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646783673349
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\n",
        "print(rest_endpoint)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646783673603
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "interactive_auth = InteractiveLoginAuthentication()\n",
        "auth_header = interactive_auth.get_authentication_header()\n",
        "print(\"Authentication header ready.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646783673877
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "experiment_name = 'mslearn-house-prices-pipeline'\n",
        "\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=auth_header, \n",
        "                         json={\"ExperimentName\": experiment_name})\n",
        "run_id = response.json()[\"Id\"]\n",
        "run_id"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646783674476
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\n",
        "\n",
        "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
        "published_pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646783677162
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
        "\n",
        "# Submit the Pipeline every Monday at 00:00 UTC\n",
        "recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, week_days=[\"Monday\"], time_of_day=\"00:00\")\n",
        "weekly_schedule = Schedule.create(ws, name=\"weekly-houses-training\", \n",
        "                                  description=\"Based on time\",\n",
        "                                  pipeline_id=published_pipeline.id, \n",
        "                                  experiment_name='mslearn-houses-pipeline', \n",
        "                                  recurrence=recurrence)\n",
        "print('Pipeline scheduled.')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646783677683
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schedules = Schedule.list(ws)\n",
        "schedules"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646783677974
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_experiment = ws.experiments.get('mslearn-houses-pipeline')\n",
        "latest_run = list(pipeline_experiment.get_runs())[0]\n",
        "\n",
        "latest_run.get_details()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646783678555
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}